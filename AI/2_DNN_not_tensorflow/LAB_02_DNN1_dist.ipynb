{"cells":[{"cell_type":"markdown","metadata":{},"source":["AI Programming - SW Lee"]},{"cell_type":"markdown","metadata":{},"source":["# Lab 02: Simple Deep Neural Network\n","## Exercise: Predicting MNIST Digits"]},{"cell_type":"markdown","metadata":{"id":"NhC9a_u5Ta4u"},"source":["### Prepare Mini-MNIST Dataset from Scikit-Learn\n","http://yann.lecun.com/exdb/mnist/"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np # 넘파이 사용\n","from sklearn.datasets import load_digits # 손글씨 데이터셋 사용\n","from sklearn.model_selection import train_test_split # 훈련 데이터와 테스트 데이터 분리\n","from sklearn.preprocessing import StandardScaler  # 표준화\n","import matplotlib.pyplot as plt  # 그래프 그리기"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"MboBxtwcTa41"},"outputs":[],"source":["# 1. 데이터 로드\n","# skearn의 load_digits()를 이용하여 손글씨 데이터를 로드한다.\n","digits = load_digits()\n","\n","# 2. 데이터 전처리\n","# digits.images는 1797개의 8x8 픽셀 이미지 데이터를 가지고 있다. (1797, 8, 8) shape의 3차원 배열\n","# digits.target은 1797개의 이미지 데이터에 대한 정답 레이블을 가지고 있다.\n","# digits_df는 1797개의 이미지 데이터를 1차원 배열로 변환한 데이터이다. shape는 (1797, 64)\n","digits_df = digits.images.reshape((len(digits.target), -1))\n","\n","# digits_tf는 1797개의 이미지 데이터에 대한 정답 레이블을 가지고 있다.\n","digits_tf = digits.target\n","\n","# 3. 데이터 분할\n","# sklearn의 train_test_split()을 이용하여 데이터를 학습 데이터와 테스트 데이터로 나눈다.\n","# test_size는 0.20으로 설정하였다. 즉, 80%의 데이터를 학습 데이터로, 20%의 데이터를 테스트 데이터로 사용한다.\n","X_train_org, X_test_org, y_train_num, y_test = train_test_split(digits_df, digits_tf, test_size= 0.20, random_state= 101)\n","\n","# StandardScaler를 이용하여 데이터를 정규화한다.\n","# digits 데이터는 [0, 16]의 범위를 가지고 있어서 너무 큰 지수값을 가지게 되므로 정규분포의 [0, 1]로 만들어주는 것이 좋다.\n","# StandardScaler를 사용하여 데이터를 평균이 0이고 분산이 1인 정규 분포로 변환합니다.\n","sc = StandardScaler()\n","# 학습 데이터에 대해 스케일링을 적용하고, 변환된 데이터를 X_train에 저장합니다.\n","X_train = sc.fit_transform(X_train_org)\n","# 테스트 데이터에는 학습 데이터에서 학습된 스케일링을 동일하게 적용합니다.\n","X_test = sc.transform(X_test_org)\n","\n","# 3. 클래스 레이블을 원-핫 인코딩으로 변환\n","# 손글씨 데이터는 0부터 9까지의 숫자로 이루어져 있으므로, 10개의 클래스로 분류할 수 있다.\n","n_classes = 10\n","\n","# y_train_num은 (N,) shape의 1차원 배열이다. 이를 (N, 10) shape의 2차원 배열로 변환한다.\n","y_train = np.zeros((y_train_num.shape[0],10))\n","\n","# 각 샘플에 대해 해당하는 클래스에 1을 부여한다.\n","# 예를 들어\n","# y_train_num = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] 일 때\n","# y_train = [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","#            [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n","#            [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n","#            [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n","#            [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n","#            [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n","#            [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n","#            [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n","#            [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n","#            [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]\n","# 위와 같이 변환한다.\n","for i in range(n_classes): # 0부터 9까지\n","    y_train[:,i] = (y_train_num == i) # y_train_num과 i가 같으면 1, 다르면 0\n"]},{"cell_type":"markdown","metadata":{},"source":["Define Utility Functions"]},{"cell_type":"markdown","metadata":{},"source":["Sigmoid function can be defined as:\n","\n","$$ \\text{sigmoid}(x) = {1 \\over {1 + e^{-x}}} = {e^{x} \\over {1 + e^{x}}} $$\n","\n","Sigmoid function takes numbers between $[-\\infty, \\infty]$ and gives back numbers between $[0, 1]$.<br>\n","However, the corresponding numpy implementation warns overflow for large negative inputs.<br>\n","The function below is the implementation of numerically stable sigmoid. Complete the code **without using `if` statement**."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def mySigmoid(x):\n","    ### START CODE HERE ###\n","\n","    positive = x >= 0      # boolean array of positive numbers\n","    x_p = 1 / (1 + np.exp(-x))          # array of positive x\n","    x_n = np.exp(x) / (1 + np.exp(x))          # array of negative x\n","    x = np.where(positive, x_p, x_n)            # apply sigmoid function for both x_p and x_n\n","\n","    ### END CODE HERE ###\n","    return x # 시그모이드 함수를 적용한 결과를 반환"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_6532\\1714061335.py:5: RuntimeWarning: overflow encountered in exp\n","  x_p = 1 / (1 + np.exp(-x))          # array of positive x\n","C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_6532\\1714061335.py:6: RuntimeWarning: overflow encountered in exp\n","  x_n = np.exp(x) / (1 + np.exp(x))          # array of negative x\n","C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_6532\\1714061335.py:6: RuntimeWarning: invalid value encountered in divide\n","  x_n = np.exp(x) / (1 + np.exp(x))          # array of negative x\n"]},{"data":{"text/plain":["array([0.5, 1. , 0. ])"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["mySigmoid(np.array([0.0, 1000.0, -1000.0]))"]},{"cell_type":"markdown","metadata":{},"source":["Softmax function can be defined as:\n","\n","$$ \\text{softmax}(x_i) = {e^{x_i} \\over {\\sum_{k=1}^n e^{x_k}}} $$\n","\n","Softmax function also takes numbers between $[-\\infty, \\infty]$ and gives back numbers between $[0, 1]$.<br>\n","Therefore, this function has the same overflow problem for large positive inputs.<br>\n","The function below is the implementation of numerically stable softmax.<br>\n","You can make the softmax stable by multiplying $e^{-M}$ to both numerator and denominator. <br>\n","Complete the code **without using `if` statement**."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# define softmax. Assume (b, s)\n","# 소프트맥스 함수는 신경망의 출력층에서 사용되는 활성화 함수로, 각 클래스에 대한 확률 분포를 생성합니다. 이를 통해 모델이 각 클래스에 속할 확률 값을 출력할 수 있게 합니다. \n","def mySoftmax(x):\n","    ### START CODE HERE ###\n","\n","    x = x - np.max(x, axis=-1, keepdims=True)        # make x sufficiently small\n","    x = np.exp(x)        # execute exponential function\n","    x = x / np.sum(x, axis=-1, keepdims=True)        # calculate softmax\n","\n","    ### END CODE HERE ###\n","    return x"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["array([0., 1., 0.])"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["mySoftmax(np.array([0.0, 1000.0, -1000.0])) # 소프트맥스 함수를 통과한 결과"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(1797, 64)\n","(1437, 64)\n","(1437, 10)\n","[ 0.  0.  0.  9. 16.  6.  0.  0.  0.  0.  4. 15.  6. 15.  0.  0.  0.  0.\n","  8. 11.  9. 11.  0.  0.  0.  0.  8. 16. 14.  2.  0.  0.  0.  0. 11. 16.\n"," 13.  0.  0.  0.  0.  6. 14.  2. 12.  9.  0.  0.  0.  5. 16. 11.  5. 13.\n","  4.  0.  0.  0.  3.  8. 13. 16.  9.  0.]\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 200x200 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["The number is 2\n"]}],"source":["# 데이터 1797개이고 8*8=64개의 픽셀을 가지고 있으므로, 입력 노드의 개수는 64개이다.\n","print(digits_df.shape)\n","# 데이터를 80%의 학습 데이터와 20%의 테스트 데이터로 나누었으므로, 학습 데이터는 1437개, 테스트 데이터는 360개이다.\n","print(X_train.shape)\n","# 데이터를 80%의 학습 데이터와 20%의 테스트 데이터로 나누었으므로, 학습 데이터는 1437개, 테스트 데이터는 360개이다.\n","# 또한 10개의 클래스로 분류하므로, 출력 노드의 개수는 10개이다.\n","print(y_train.shape)\n","# 학습 데이터의 첫 번째 샘플을 출력한다.\n","print(X_train_org[0]) # x_train_org은 0~16의 값으로 이루어진 64개의 픽셀값을 가지고 있음\n","\n","# 학습 데이터의 첫 번째 샘플을 이미지로 출력한다.\n","idx = np.random.randint(X_train.shape[0])\n","# 이미지 데이터는 8*8=64개의 픽셀을 가지고 있으므로, 8*8의 이미지로 reshape한다.\n","dimage = X_train_org[idx].reshape((8,8))\n","# 이미지를 출력한다.\n","plt.figure(figsize=(2, 2))\n","# 이미지를 흑백으로 출력한다.\n","plt.gray()\n","# matshow()는 행렬 데이터를 이미지로 출력하는 함수이다. (행렬 데이터, fignum=1)은 행렬 데이터를 이미지로 출력하고, 이미지를 출력할 창의 번호를 1로 설정한다.\n","plt.matshow(dimage, fignum=1)\n","# 이미지를 출력한다.\n","plt.show()\n","# 해당 이미지의 정답 레이블을 출력한다.\n","print('The number is', y_train_num[idx])\n"]},{"cell_type":"markdown","metadata":{},"source":["### Simple DNN for Digit Classification"]},{"cell_type":"markdown","metadata":{},"source":["Define Model Class"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["class myDenseLayer:\n","    def __init__(self, n_out, n_in): # n_out: 출력 노드의 개수, n_in: 입력 노드의 개수\n","        self.wegt = np.empty((n_out, n_in)) # 가중치\n","        self.bias = np.zeros((n_out)) # 편향\n","        self.saved_x = None     # store x to use while backpropagation\n","\n","    def forward(self, x):       # (b, i) b: batch size, i: input size\n","        ### START CODE HERE ###\n","\n","        self.saved_x = x     # keep it for backward\n","        # if x.ndim == 3:\n","            # x_lin = self.wegt @ x + self.bias\n","        # # x_lin = np.einsum('abc,db->adc', x, self.wegt) + self.bias     # Linear Prediction\n","        # else:\n","        # x_lin = x @ self.wegt.T + self.bias     # Linear Prediction\n","\n","        x_lin = (self.wegt @ x.T).T + self.bias  # 첫 번째 방식\n","        ### END CODE HERE ###\n","        return x_lin\n","\n","    def backward(self, x, x_in):\n","        # x = dJ/dz, x_in = 입력 값\n","        # assert np.array_equal(self.saved_x, x_in), 'x_in does not equal to input X.'\n","        \n","        # print(f\"x: {x.shape}, x_in: {x_in.shape}, self.wegt: {self.wegt.shape}\")\n","        \n","        ### START CODE HERE ###\n","        # 가중치에 대한 기울기 계산 (차원에 맞추어 연산)\n","        dw = x.T @ x_in  # @ 연산자를 사용하여 행렬 곱셈 (x.T의 shape과 x_in의 shape에 맞춰 연산)\n","\n","        # 편향에 대한 기울기 계산\n","        db = np.sum(x, axis=0)  # 각 출력에 대한 편향의 기울기\n","        \n","        # 이전 레이어로 전달할 기울기 계산\n","        wdJdz = x @ self.wegt  # wegt는 가중치, x는 현재 레이어의 출력, @ 연산자로 행렬 곱셈\n","        \n","        # print(f\"dw: {dw.shape}, db: {db.shape}, wdJdz: {wdJdz.shape}\")\n","\n","        ### END CODE HERE ###\n","        return dw, db, wdJdz # dJ/dw, dJ/db, w*dJ/dz (이전 레이어로 전달할 기울기)\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[ 3.23890168  3.05091188 -3.32627831]\n","  [ 0.388114    3.36724875  1.06158492]\n","  [ 3.10267869  1.87570497 -1.8326582 ]]\n","\n"," [[-7.60581826  2.36703751 -1.16423539]\n","  [ 3.48035012  2.41940644 -0.13917734]\n","  [ 1.20541315  2.07585619 -1.5435161 ]]]\n"]}],"source":["np.random.seed(0) # 랜덤 시드 고정\n"," \n","tmp = myDenseLayer(3,5) # 3개의 출력 노드, 5개의 입력 노드\n","tmp.wegt = np.random.randn(3,5) # 가중치\n","tmp.bias = np.random.randn(3) # 편향\n","\n","print(tmp.forward(np.random.randn(2,5,3))) # 2,5,3의 shape를 갖음"]},{"cell_type":"markdown","metadata":{},"source":["**Expected Outputs**\n","\n","```\n","[[[ 3.23890168  3.05091188 -3.32627831]\n","  [ 0.388114    3.36724875  1.06158492]\n","  [ 3.10267869  1.87570497 -1.8326582 ]]\n","\n"," [[-7.60581826  2.36703751 -1.16423539]\n","  [ 3.48035012  2.41940644 -0.13917734]\n","  [ 1.20541315  2.07585619 -1.5435161 ]]]\n","```"]},{"cell_type":"markdown","metadata":{},"source":["Define Backpropagation of Activation Functions"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# sigmoid 함수의 기울기를 계산하는 함수를 구현합니다.\n","def dJdz_sigmoid(wdJdz_upper, az):\n","    ### START CODE HERE ###\n","\n","    dJdz = wdJdz_upper * az * (1 - az)            # backpropagation through activation function\n","    \n","    ### END CODE HERE ###\n","    return dJdz\n","\n","# softmax 함수의 기울기를 계산하는 함수를 구현합니다.\n","def dJdz_softmax(y_hat, y):\n","    ### START CODE HERE ###\n","    \n","    dJdz = y_hat - y            # backpropagation through activation function\n","    \n","    ### END CODE HERE ###\n","    return dJdz"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[-4.90531647 -0.64834065 -1.89126428]\n","[ 0.53948992 -0.29540078 -1.55749236]\n"]}],"source":["np.random.seed(0) # 랜덤 시드 고정\n","\n","print(dJdz_sigmoid(np.random.randn(3),np.random.randn(3))) # 3개의 랜덤한 숫자를 입력으로 넣어 테스트\n","print(dJdz_softmax(np.random.randn(3),np.random.randn(3))) # 3개의 랜덤한 숫자를 입력으로 넣어 테스트"]},{"cell_type":"markdown","metadata":{},"source":["**Expected Outputs**\n","\n","```\n","[-4.90531647 -0.64834065 -1.89126428]\n","[ 0.53948992 -0.29540078 -1.55749236]\n","```"]},{"cell_type":"markdown","metadata":{},"source":["Define Training Functions<br>"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["def my_forward(l1, l2, l3, X_in):  # l1, l2, l3: 레이어, X_in: 입력 데이터\n","    ### START CODE HERE ###\n","\n","    a_1 = mySigmoid(l1.forward(X_in))               # first stage forward\n","    a_2 = mySigmoid(l2.forward(a_1))                    # second stage forward\n","    a_3 = mySoftmax(l3.forward(a_2))                    # third stage forward\n","\n","    ### END CODE HERE ###\n","    return a_1, a_2, a_3\n","\n","def my_backward(l1, l2, l3, a_1, a_2, a_3, X_in, y_true):  # l1, l2, l3: 레이어, a_1, a_2, a_3: 각 스테이지의 출력, X_in: 입력 데이터, y_true: 정답 레이블\n","    ### START CODE HERE ###\n","    \n","    dw_3, db_3, wdJdz_3 = l3.backward(dJdz_softmax(a_3, y_true) , a_2)    # go through 3rd stage backward\n","    dw_2, db_2, wdJdz_2 = l2.backward(dJdz_sigmoid(wdJdz_3, a_2), a_1)    # go through 2nd stage backward\n","    dw_1, db_1, _       = l1.backward(dJdz_sigmoid(wdJdz_2, a_1)  , X_in)    # go through 1st stage backward\n","\n","    ### END CODE HERE ###\n","\n","    d_1 = [dw_1, db_1] # dJ/dw, dJ/db\n","    d_2 = [dw_2, db_2] # dJ/dw, dJ/db\n","    d_3 = [dw_3, db_3] # dJ/dw, dJ/db\n","    \n","    return d_1, d_2, d_3 # 각 레이어의 기울기\n","\n","def my_loss(l1, l2, l3, X_in, y_true): # l1, l2, l3: 레이어, X_in: 입력 데이터, y_true: 정답 레이블\n","    ### START CODE HERE ###\n","\n","    a_1 = mySigmoid(l1.forward(X_in))               # first stage forward\n","    a_2 = mySigmoid(l2.forward(a_1))                    # second stage forward\n","    a_3 = mySoftmax(l3.forward(a_2))    #1437                # third stage forward\n","\n","    # print(f\"y_true: {y_true.shape}, a_3: {a_3.shape}\")\n","    loss = -np.sum(y_true * np.log(a_3) + 1e-9) / y_true.shape[0]   # y_true와 a_3는 동일한 shape이어야 함         # calculate loss\n","\n","    ### END CODE HERE ###\n","    return loss\n","    \n","def my_predict(l1, l2, l3, X_in): # l1, l2, l3: 레이어, X_in: 입력 데이터\n","    ### START CODE HERE ###\n","\n","    a_1 = mySigmoid(l1.forward(X_in))               # first stage forward\n","    a_2 = mySigmoid(l2.forward(a_1))                    # second stage forward\n","    a_3 = mySoftmax(l3.forward(a_2))                    # third stage forward\n","    # 행기준으로 가장 큰 값의 인덱스를 반환한다.\n","\n","    pred = np.argmax([a_3], axis=-1).reshape(-1)                  # make prediction\n","\n","    ### END CODE HERE ###\n","    return pred # 예측값"]},{"cell_type":"markdown","metadata":{},"source":["Create a NN model and check the matrix dimensions"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"DT0rMw-rTa5A"},"outputs":[{"name":"stdout","output_type":"stream","text":["(1437, 64) (1437, 10)\n","(80, 64) (80,)\n","(70, 80) (70,)\n","(10, 70) (10,)\n"]}],"source":["n_inputs  = 64 # n_inputs: 입력 노드의 개수\n","n_hidden1 = 80 # n_hidden1: 첫 번째 은닉층의 노드 개수(출력 노드의 개수)\n","n_hidden2 = 70 # n_hidden2: 두 번째 은닉층의 노드 개수(출력 노드의 개수)\n","n_classes = 10 # n_classes: 출력 노드의 개수\n","\n","l1 = myDenseLayer(n_hidden1, n_inputs) # 첫 번째 은닉층\n","l2 = myDenseLayer(n_hidden2, n_hidden1) # 두 번째 은닉층\n","l3 = myDenseLayer(n_classes, n_hidden2) # 출력층\n","\n","print(X_train.shape, y_train.shape) # 학습 데이터의 shape 출력\n","print(l1.wegt.shape, l1.bias.shape) # 첫 번째 은닉층의 가중치와 편향 shape 출력\n","print(l2.wegt.shape, l2.bias.shape) # 두 번째 은닉층의 가중치와 편향 shape 출력\n","print(l3.wegt.shape, l3.bias.shape)  # 출력층의 가중치와 편향 shape 출력"]},{"cell_type":"markdown","metadata":{},"source":["**Expected Outputs**\n","\n","```\n","(1437, 64) (1437, 10)\n","(80, 64) (80,)\n","(70, 80) (70,)\n","(10, 70) (10,)\n","```"]},{"cell_type":"markdown","metadata":{},"source":["Weight Initialization"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# Weights are initialized to...\n","l1.wegt = np.random.randn(n_hidden1, n_inputs) # 첫 번째 은닉층의 가중치를 랜덤으로 초기화\n","l2.wegt = np.random.randn(n_hidden2, n_hidden1) # 두 번째 은닉층의 가중치를 랜덤으로 초기화\n","l3.wegt = np.random.randn(n_classes, n_hidden2) # 출력층의 가중치를 랜덤으로 초기화"]},{"cell_type":"markdown","metadata":{},"source":["Training Simple Neural Network Model (3 layer model) (<b>Update weights</b>)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55777,"status":"ok","timestamp":1649259680196,"user":{"displayName":"Seong-Won Lee","userId":"14858304546124675216"},"user_tz":-540},"id":"qODinrZlTa5C","outputId":"8237949a-964a-49cd-f3e9-fb65759245e7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch:  500,  loss: 0.01897377\n","Epoch: 1000,  loss: 0.00670544\n","Epoch: 1500,  loss: 0.00427039\n","Epoch: 2000,  loss: 0.00129886\n","Epoch: 2500,  loss: 0.00083281\n","Epoch: 3000,  loss: 0.00062687\n","Epoch: 3500,  loss: 0.00050742\n","Epoch: 4000,  loss: 0.00042690\n","Epoch: 4500,  loss: 0.00036628\n","Epoch: 5000,  loss: 0.00031914\n"]}],"source":["# alpha: learning rate, lamda: regularization factor\n"," \n","alpha = 0.01  # 학습률\n","n_epochs = 5000 # 학습 횟수\n","\n","# 학습을 시작한다.\n","for epoch in range(n_epochs):\n","    ### START CODE HERE ###\n","\n","    # Forward Path\n","    # print(f\"X train: {X_train.shape}\")\n","    a_1, a_2, a_3 = my_forward(l1, l2, l3, X_train )   # forward path\n","    \n","    # print(f\"a_1 = {a_1.shape}, a_2 = {a_2.shape}, a_3 = {a_3.shape}\")\n","    # Backward Path\n","    d_1, d_2, d_3 = my_backward(l1, l2, l3, a_1, a_2, a_3, X_train, y_train)   # backward path\n","\n","    ### END CODE HERE ###\n","\n","    dw_1, db_1 = d_1\n","    dw_2, db_2 = d_2\n","    dw_3, db_3 = d_3\n","\n","    # Update weights and biases\n","    ### START CODE HERE ###\n","    \n","    l3.wegt = l3.wegt - alpha * dw_3  # 가중치 업데이트 (정규화 항 없음)\n","    l3.bias = l3.bias - alpha * db_3  # 편향 업데이트\n","\n","    l2.wegt = l2.wegt - alpha * dw_2  # 가중치 업데이트 (정규화 항 없음)\n","    l2.bias = l2.bias - alpha * db_2  # 편향 업데이트\n","\n","    l1.wegt = l1.wegt - alpha * dw_1  # 가중치 업데이트 (정규화 항 없음)\n","    l1.bias = l1.bias - alpha * db_1  # 편향 업데이트\n","    ### END CODE HERE ###\n","\n","    # Print loss\n","    if ((epoch+1)%500==0): # 500번째 epoch마다 손실을 출력한다.\n","        loss_J = my_loss(l1, l2, l3, X_train, y_train) # 손실 계산\n","        print('Epoch: %4d,  loss: %10.8f' % (epoch+1, loss_J)) # 손실 출력"]},{"cell_type":"markdown","metadata":{},"source":["Evaluate Model Performance"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":292,"status":"ok","timestamp":1649259686353,"user":{"displayName":"Seong-Won Lee","userId":"14858304546124675216"},"user_tz":-540},"id":"xMvLn6SJTa5D","outputId":"229cafc3-c9c5-4dd2-f7bc-d4cdf90c4d46"},"outputs":[{"data":{"text/plain":["0.9361111111111111"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.metrics import accuracy_score # 정확도 계산 함수\n","\n","y_pred = my_predict(l1, l2, l3, X_test) # 테스트 데이터에 대한 예측값 계산\n"," \n","accuracy_score(y_pred, y_test) # 정확도 출력"]},{"cell_type":"markdown","metadata":{"id":"WieUxPz9Ta5F"},"source":["Neural Network from scikit-learn"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3086,"status":"ok","timestamp":1649259694763,"user":{"displayName":"Seong-Won Lee","userId":"14858304546124675216"},"user_tz":-540},"id":"w8AcitiaTa5G","outputId":"09455c7b-a58f-4492-b5cb-431eab436f6c"},"outputs":[{"data":{"text/plain":["0.9666666666666667"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.neural_network import MLPClassifier  # 다층 퍼셉트론(MLP)을 구현하는 클래스\n","\n","mlp = MLPClassifier(\n","    hidden_layer_sizes=(80, 70, ),  # 은닉층의 크기를 정의. 여기서는 2개의 은닉층을 사용하며, 첫 번째 은닉층에는 80개의 뉴런, 두 번째 은닉층에는 70개의 뉴런을 사용\n","    activation='logistic',          # 활성화 함수로 'logistic' 함수를 사용 (로지스틱 시그모이드 함수).\n","    solver='sgd',                   # 최적화 알고리즘으로 확률적 경사 하강법(SGD)을 사용.\n","    alpha=0.01,                     # 학습률에 곱해지는 상수. 학습률을 조절하는 하이퍼파라미터\n","    learning_rate_init=0.01,        # 경사 하강법에서 가중치 업데이트의 크기를 결정\n","    max_iter=1000,                   # 최대 반복 횟수. 모델 학습 시 최대 1000번의 반복까지 수행. 이 횟수에 도달하면 학습이 멈춤\n",")\n","# Training/Fitting the Model\n","mlp.fit(X_train, y_train_num) # 학습 데이터에 대해 모델 학습\n","\n","# Making Predictions\n","s_pred = mlp.predict(X_test) # 테스트 데이터에 대한 예측값 출력\n","accuracy_score(s_pred, y_test) # 정확도 출력"]},{"cell_type":"markdown","metadata":{"id":"BmZQrDH9n0PK"},"source":["### Test Model with a random sample\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 200x200 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["My prediction is 4\n","sk prediction is 4\n","Actual number is 4\n"]}],"source":["idx = np.random.randint(X_test.shape[0]) # 랜덤한 인덱스 선택\n","dimage = X_test_org[idx].reshape((8,8)) # 이미지 데이터를 8*8로 reshape\n","plt.figure(figsize=(2, 2)) # 이미지 크기 설정\n","plt.gray() # 흑백 이미지로 출력\n","plt.matshow(dimage, fignum=1) # 이미지 출력\n","plt.show() # 이미지 출력\n","\n","X_input = np.expand_dims(X_test[idx], 0) # 입력 데이터의 shape을 (1, 64)로 변환\n","\n","# print(X_input.shape) # 입력 데이터의 shape 출력\n","y_pred = my_predict(l1, l2, l3, X_input) # 내가 구현한 모델로 예측\n","\n","s_pred = mlp.predict(X_input) # sklearn의 모델로 예측\n","\n","print('My prediction is ' + str(y_pred[0])) # 내가 구현한 모델의 예측\n","print('sk prediction is ' + str(s_pred[0])) # sklearn의 모델의 예측\n","print('Actual number is ' + str(y_test[idx])) # 실제 정답 레이블"]},{"cell_type":"markdown","metadata":{},"source":["(c) 2024 SW Lee"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"ML_L06_01_MNIST.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.9.9 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"19c3f3f12223855b5e5811df3b51e2142b7f938327ffb9b9a66299337f7b60d0"}}},"nbformat":4,"nbformat_minor":0}
